{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Available scene list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "    \n",
    "f = open('../scene.json', \"r\")\n",
    "scene_json = json.load(f)\n",
    "\n",
    "scene_list = list(scene_json.keys())\n",
    "scene_dict = scene_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate scene csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def generate_csv(s_idx, r_idx, sp_nums=None):\n",
    "    \n",
    "    scene_id = scene_list[s_idx]\n",
    "    \n",
    "    # Data (image and ground truth) directory\n",
    "    ds_pth = f\"E:/Workspace/Datasets/iGibson-dataset/iGibson-pano-data/\"\n",
    "    ds_pth = f\"{ds_pth}/{scene_id}/{r_idx}/\"\n",
    "    if sp_nums is None:\n",
    "        sp_nums = len(os.listdir(f\"{ds_pth}/\"))\n",
    "    \n",
    "    # Map (wall and object) directory\n",
    "    mp_pth = f\"E:/Workspace/Datasets/iGibson-dataset/iGibson-area/\"\n",
    "    mp_pth = f\"{mp_pth}/{scene_id}/{r_idx}/wmap.txt\"\n",
    "    \n",
    "    # Store data directory in csv\n",
    "    tgt_pth = f\"E:/Workspace/Datasets/iGibson-dataset/iGibson-pano-csv/\"\n",
    "    if not os.path.exists(f\"{tgt_pth}/{scene_id}/\"):\n",
    "        os.makedirs(f\"{tgt_pth}/{scene_id}/\")\n",
    "    tgt_pth = f\"{tgt_pth}/{scene_id}/{r_idx}.csv\"\n",
    "    \n",
    "    scene_df = {\n",
    "        \"gt\": [],\n",
    "        \"rgb\": [],\n",
    "        \"d\": [],\n",
    "        \"mp\": []\n",
    "    }\n",
    "    \n",
    "    for i in range(sp_nums):\n",
    "        \n",
    "        gt_pth = f\"{ds_pth}/{i}/gt/\"\n",
    "        scene_df[\"gt\"].append(gt_pth)\n",
    "        \n",
    "        rgb_pth = f\"{ds_pth}/{i}/rgb/\"\n",
    "        scene_df[\"rgb\"].append(rgb_pth)\n",
    "        \n",
    "        # d_pth = f\"{ds_pth}/{i}/d_processed/\"\n",
    "        d_pth = f\"{ds_pth}/{i}/d/\"\n",
    "        scene_df[\"d\"].append(d_pth)\n",
    "        \n",
    "        scene_df[\"mp\"].append(mp_pth)\n",
    "        \n",
    "    scene_df = pd.DataFrame(scene_df)\n",
    "    scene_df.to_csv(tgt_pth, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_idx = 1\n",
    "for r_idx in range(5):\n",
    "    generate_csv(s_idx, r_idx)\n",
    "\n",
    "s_idx = 3\n",
    "for r_idx in range(2):\n",
    "    generate_csv(s_idx, r_idx)\n",
    "    \n",
    "s_idx = 4\n",
    "for r_idx in range(6):\n",
    "    generate_csv(s_idx, r_idx)\n",
    "    \n",
    "s_idx = 5\n",
    "for r_idx in range(3):\n",
    "    generate_csv(s_idx, r_idx)\n",
    "    \n",
    "s_idx = 6\n",
    "for r_idx in range(6):\n",
    "    generate_csv(s_idx, r_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "    \n",
    "f = open('../train.json', \"r\")\n",
    "scene_json = json.load(f)\n",
    "\n",
    "train_list = scene_json[\"train_list\"]\n",
    "test_list = scene_json[\"test_list\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "ds_pth = f\"E:/Workspace/Datasets/iGibson-dataset/iGibson-pano-csv\"\n",
    "\n",
    "train_df = pd.DataFrame()\n",
    "for idx in range(len(train_list)):\n",
    "    \n",
    "    train_item = pd.read_csv(\n",
    "        f\"{ds_pth}/{train_list[idx]}\"\n",
    "    )\n",
    "    train_df = pd.concat((train_df, train_item))\n",
    "\n",
    "train_df.to_csv(\n",
    "    f\"{ds_pth}/train.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "test_df = pd.DataFrame()\n",
    "for idx in range(len(test_list)):\n",
    "    \n",
    "    test_item = pd.read_csv(\n",
    "        f\"{ds_pth}/{test_list[idx]}\"\n",
    "    )\n",
    "    test_df = pd.concat((test_df, test_item))\n",
    "\n",
    "test_df.to_csv(\n",
    "    f\"{ds_pth}/test.csv\",\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validate csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([424, 417, 505, 488, 278], dtype='int64')\n",
      "Index(['gt', 'rgb', 'd', 'mp'], dtype='object')\n",
      "E:/Workspace/Datasets/iGibson-dataset/iGibson-pano-data//Ihlen_1_int/2//24/gt/\n",
      "E:/Workspace/Datasets/iGibson-dataset/iGibson-pano-data//Ihlen_1_int/2//17/rgb/\n",
      "E:/Workspace/Datasets/iGibson-dataset/iGibson-pano-data//Merom_1_int/0//5/d/\n",
      "E:/Workspace/Datasets/iGibson-dataset/iGibson-area//Merom_0_int/0/wmap.txt\n",
      "Index([20, 18, 83, 108, 139], dtype='int64')\n",
      "Index(['gt', 'rgb', 'd', 'mp'], dtype='object')\n",
      "E:/Workspace/Datasets/iGibson-dataset/iGibson-pano-data//Beechwood_1_int/4//20/gt/\n",
      "E:/Workspace/Datasets/iGibson-dataset/iGibson-pano-data//Beechwood_1_int/4//18/rgb/\n",
      "E:/Workspace/Datasets/iGibson-dataset/iGibson-pano-data//Merom_0_int/1//33/d/\n",
      "E:/Workspace/Datasets/iGibson-dataset/iGibson-area//Merom_1_int/1/wmap.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "ds_pth = f\"E:/Workspace/Datasets/iGibson-dataset/iGibson-pano-csv\"\n",
    "\n",
    "train_pth = f\"{ds_pth}/train.csv\"\n",
    "train_df = pd.read_csv(train_pth)\n",
    "\n",
    "train_sample = train_df.sample(n=5)\n",
    "print(train_sample.index)\n",
    "print(train_sample.columns)\n",
    "\n",
    "print(train_sample[\"gt\"][train_sample.index[0]])\n",
    "print(train_sample[\"rgb\"][train_sample.index[1]])\n",
    "print(train_sample[\"d\"][train_sample.index[2]])\n",
    "print(train_sample[\"mp\"][train_sample.index[3]])\n",
    "\n",
    "test_pth = f\"{ds_pth}/test.csv\"\n",
    "test_df = pd.read_csv(test_pth)\n",
    "\n",
    "test_sample = test_df.sample(n=5)\n",
    "print(test_sample.index)\n",
    "print(test_sample.columns)\n",
    "\n",
    "print(test_sample[\"gt\"][test_sample.index[0]])\n",
    "print(test_sample[\"rgb\"][test_sample.index[1]])\n",
    "print(test_sample[\"d\"][test_sample.index[2]])\n",
    "print(test_sample[\"mp\"][test_sample.index[3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Panorama dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from utils import *\n",
    "\n",
    "\n",
    "class IgibsonPanorama(Dataset):\n",
    "    \n",
    "    def __init__(self, csv_pth):\n",
    "        super(IgibsonPanorama, self).__init__()\n",
    "        \n",
    "        self.data = pd.read_csv(csv_pth)\n",
    "        \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        # Read ground truth\n",
    "        gt_pth = self.data[\"gt\"][index]\n",
    "        gt = read_gt(gt_pth)\n",
    "        gt = gt[0, ...]\n",
    "        \n",
    "        # Read observation\n",
    "        # obs_pth = self.data[\"rgb\"][index]\n",
    "        # obs = read_obs(obs_pth)\n",
    "        \n",
    "        obs_pth = self.data[\"d\"][index]\n",
    "        obs = read_depth(obs_pth)\n",
    "        \n",
    "        # Read map\n",
    "        mp_pth = self.data[\"mp\"][index]\n",
    "        mp, mp_mask = read_mp(mp_pth)\n",
    "        \n",
    "        return (gt, obs, mp, mp_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth: torch.Size([4, 3])\n",
      "Observation torch.Size([4, 1, 8, 3, 224, 224])\n",
      "Map torch.Size([4, 20, 4])\n",
      "Map mask torch.Size([4, 20])\n",
      "Map mask tensor([[1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:23<00:00,  6.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth: torch.Size([4, 3])\n",
      "Observation torch.Size([4, 1, 8, 3, 224, 224])\n",
      "Map torch.Size([4, 20, 4])\n",
      "Map mask torch.Size([4, 20])\n",
      "Map mask tensor([[1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:07<00:00,  6.68it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "train_pth = \"e:\\Workspace\\Datasets\\iGibson-dataset\\iGibson-pano-csv/train.csv\"\n",
    "train_dataset = IgibsonPanorama(train_pth)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "gt, obs, mp, mp_mask = next(iter(train_dataloader))\n",
    "print(f\"Ground truth: {gt.shape}\")\n",
    "print(f\"Observation {obs.shape}\")\n",
    "print(f\"Map {mp.shape}\")\n",
    "print(f\"Map mask {mp_mask.shape}\")\n",
    "print(f\"Map mask {mp_mask}\")\n",
    "\n",
    "for gt, obs, mp, mp_mask in tqdm(train_dataloader):\n",
    "    pass\n",
    "\n",
    "test_pth = \"e:\\Workspace\\Datasets\\iGibson-dataset\\iGibson-pano-csv/test.csv\"\n",
    "test_dataset = IgibsonPanorama(test_pth)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "gt, obs, mp, rel = next(iter(test_dataloader))\n",
    "print(f\"Ground truth: {gt.shape}\")\n",
    "print(f\"Observation {obs.shape}\")\n",
    "print(f\"Map {mp.shape}\")\n",
    "print(f\"Map mask {mp_mask.shape}\")\n",
    "print(f\"Map mask {mp_mask}\")\n",
    "\n",
    "for gt, obs, mp, rel in tqdm(test_dataloader):\n",
    "    pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "igibson",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
